# CNN Mini Projects

This repository is a collection of small CNN experiments created for learning and practice. Each experiment focuses on understanding a specific concept such as data loading, model training, evaluation, and experimentation with convolutional neural networks using simple datasets.

1. [Fake Data Multiclass Classification](fake_data_multiclass.ipynb): This mini-project demonstrates a lightweight image classification pipeline in PyTorch using torchvision.datasets.FakeData to simulate a 10-class dataset (3×32×32 images). It focuses on understanding the vision training workflow end-to-end: dataset creation with transforms (ToTensor), mini-batch loading via DataLoader, and building a minimal CNN architecture (single Conv2D → ReLU → MaxPool → Flatten → Linear classifier). The model is trained on CPU/GPU using a standard training loop with CrossEntropyLoss + Adam, showing how logits-based multi-class classification is handled in PyTorch. Training progress is tracked through an epoch-wise loss curve, making it a quick, controlled experiment to validate CNN plumbing and debug the full image-training pipeline without relying on external datasets.

2. [Double Stack Multiclass](double_stack_multiclass.ipynb): This mini-project builds an end-to-end binary classification pipeline in PyTorch using a synthetic tabular dataset generated with make_classification. It covers data splitting with train_test_split, wrapping NumPy arrays into TensorDataset, efficient batching through DataLoader, and training a simple feedforward neural network with two hidden layers, ReLU activations, and dropout for regularization. The model is trained on GPU/CPU using BCELoss with an Adam optimizer, while torchinfo.summary is used to inspect layer-wise shapes and parameter counts for clarity and debugging. Training and validation losses are tracked across epochs and visualized with a clean loss curve, making it a practical experiment for understanding tabular MLP training dynamics, overfitting behavior, and basic evaluation workflow in PyTorch.
